{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets torch accelerate seqeval scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Setup paths for Google Colab\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('/content/drive/MyDrive/574-assignment')\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'generated'\n",
    "MODEL_PATH = PROJECT_ROOT / 'models' / 'two_stage_joint'\n",
    "\n",
    "# Ensure model output directory exists\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "\n",
    "# Verify data files exist\n",
    "print(\"\\nChecking data files:\")\n",
    "for f in ['train.json', 'val.json', 'test.json', 'label_mappings.json']:\n",
    "    if (DATA_PATH / f).exists():\n",
    "        print(f\"  ✓ Found {f}\")\n",
    "    else:\n",
    "        print(f\"  ✗ Missing {f} - please upload to Google Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96551ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    DebertaV2TokenizerFast,\n",
    "    DebertaV2Model,\n",
    "    DebertaV2PreTrainedModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig\n",
    ")\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from seqeval.metrics import f1_score as seqeval_f1, classification_report\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926bec6",
   "metadata": {},
   "source": [
    "## 1. Configuration & Label Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f260a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'model_name': 'microsoft/deberta-v3-base',\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 2e-5,\n",
    "    'head_learning_rate': 1e-4,  # Higher LR for classification heads\n",
    "    'max_length': 128,\n",
    "    'weight_decay': 0.01,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    \n",
    "    # Staged training\n",
    "    'stage1_epochs': 3,      # Tool + NER only\n",
    "    'stage2_epochs': 7,      # Joint training\n",
    "    'finetune_epochs': 5,    # Fine-tuning with lower LR\n",
    "    'warmup_ratio': 0.1,\n",
    "    \n",
    "    # Loss weights\n",
    "    'tool_loss_weight': 1.0,\n",
    "    'intent_loss_weight': 1.0,\n",
    "    'ner_loss_weight': 1.0,\n",
    "    \n",
    "    # Early stopping\n",
    "    'patience': 3,\n",
    "    \n",
    "    # Dropout\n",
    "    'classifier_dropout': 0.1,\n",
    "}\n",
    "\n",
    "# Load label mappings from generated file\n",
    "with open(DATA_PATH / 'label_mappings.json', 'r') as f:\n",
    "    LABEL_MAPPINGS = json.load(f)\n",
    "\n",
    "# Extract mappings\n",
    "TOOL_TO_IDX = LABEL_MAPPINGS['tool_to_idx']\n",
    "IDX_TO_TOOL = {int(k): v for k, v in LABEL_MAPPINGS['idx_to_tool'].items()}\n",
    "TOOLS = list(TOOL_TO_IDX.keys())\n",
    "\n",
    "TAG_TO_IDX = LABEL_MAPPINGS['tag_to_idx']\n",
    "IDX_TO_TAG = {int(k): v for k, v in LABEL_MAPPINGS['idx_to_tag'].items()}\n",
    "\n",
    "# Per-tool intent mappings (the key change from flat architecture)\n",
    "INTENT_TO_IDX_PER_TOOL = LABEL_MAPPINGS['intent_to_idx_per_tool']\n",
    "IDX_TO_INTENT_PER_TOOL = LABEL_MAPPINGS['idx_to_intent_per_tool']\n",
    "NUM_INTENTS_PER_TOOL = LABEL_MAPPINGS['num_intents_per_tool']\n",
    "\n",
    "# Global intent mapping (for reference)\n",
    "INTENT_TO_TOOL = LABEL_MAPPINGS['intent_to_tool']\n",
    "\n",
    "print(f\"Number of tools: {len(TOOLS)}\")\n",
    "print(f\"Number of NER tags: {len(TAG_TO_IDX)}\")\n",
    "print(f\"\\nIntents per tool:\")\n",
    "for tool, num in NUM_INTENTS_PER_TOOL.items():\n",
    "    print(f\"  {tool}: {num}\")\n",
    "print(f\"\\nTotal intents: {sum(NUM_INTENTS_PER_TOOL.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03f32d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4204d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(split='train'):\n",
    "    \"\"\"Load dataset from JSON file.\"\"\"\n",
    "    path = DATA_PATH / f'{split}.json'\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Loaded {len(data)} {split} samples from {path}\")\n",
    "    return data\n",
    "\n",
    "train_data = load_dataset('train')\n",
    "val_data = load_dataset('val')\n",
    "test_data = load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine sample structure\n",
    "print(\"Sample structure:\")\n",
    "print(json.dumps(train_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00c351",
   "metadata": {},
   "source": [
    "## 3. Dataset Class (Per-Tool Intent Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for two-stage joint model.\n",
    "    \n",
    "    Key difference from flat architecture:\n",
    "    - Intent labels are per-tool (categorical index, not multi-hot)\n",
    "    - Non-selected tools get intent label -100 (ignored in loss)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        text = sample['query']\n",
    "        tools = sample['tools']\n",
    "        intents = sample['intents']\n",
    "        bio_tags = sample['bio_tags']\n",
    "        \n",
    "        # Tokenize with word IDs for aligning BIO tags\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            return_offsets_mapping=True,\n",
    "            return_special_tokens_mask=True\n",
    "        )\n",
    "        \n",
    "        # Tool labels (multi-label binary)\n",
    "        tool_labels = torch.zeros(len(TOOLS))\n",
    "        for tool in tools:\n",
    "            if tool in TOOL_TO_IDX:\n",
    "                tool_labels[TOOL_TO_IDX[tool]] = 1\n",
    "        \n",
    "        # Per-tool intent labels (categorical with -100 for non-selected)\n",
    "        intent_label_character = torch.tensor(-100, dtype=torch.long)\n",
    "        intent_label_session = torch.tensor(-100, dtype=torch.long)\n",
    "        intent_label_rulebook = torch.tensor(-100, dtype=torch.long)\n",
    "        \n",
    "        for tool, intent in intents.items():\n",
    "            if tool == 'character_data' and intent in INTENT_TO_IDX_PER_TOOL['character_data']:\n",
    "                intent_label_character = torch.tensor(\n",
    "                    INTENT_TO_IDX_PER_TOOL['character_data'][intent], \n",
    "                    dtype=torch.long\n",
    "                )\n",
    "            elif tool == 'session_notes' and intent in INTENT_TO_IDX_PER_TOOL['session_notes']:\n",
    "                intent_label_session = torch.tensor(\n",
    "                    INTENT_TO_IDX_PER_TOOL['session_notes'][intent], \n",
    "                    dtype=torch.long\n",
    "                )\n",
    "            elif tool == 'rulebook' and intent in INTENT_TO_IDX_PER_TOOL['rulebook']:\n",
    "                intent_label_rulebook = torch.tensor(\n",
    "                    INTENT_TO_IDX_PER_TOOL['rulebook'][intent], \n",
    "                    dtype=torch.long\n",
    "                )\n",
    "        \n",
    "        # Align BIO tags with tokens\n",
    "        ner_labels = self._align_labels(\n",
    "            text, bio_tags, encoding, encoding['offset_mapping'][0]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'tool_labels': tool_labels,\n",
    "            'intent_label_character': intent_label_character,\n",
    "            'intent_label_session': intent_label_session,\n",
    "            'intent_label_rulebook': intent_label_rulebook,\n",
    "            'ner_labels': ner_labels,\n",
    "            'tools': tools,\n",
    "            'intents': intents\n",
    "        }\n",
    "    \n",
    "    def _align_labels(self, text, bio_tags, encoding, offset_mapping):\n",
    "        \"\"\"Align word-level BIO tags to subword tokens.\"\"\"\n",
    "        words = text.split()\n",
    "        \n",
    "        # Handle mismatch between words and bio_tags\n",
    "        if len(bio_tags) != len(words):\n",
    "            if len(bio_tags) < len(words):\n",
    "                bio_tags = bio_tags + ['O'] * (len(words) - len(bio_tags))\n",
    "            else:\n",
    "                bio_tags = bio_tags[:len(words)]\n",
    "        \n",
    "        # Create word boundaries\n",
    "        word_boundaries = []\n",
    "        current_pos = 0\n",
    "        for word in words:\n",
    "            start = text.find(word, current_pos)\n",
    "            if start == -1:\n",
    "                start = current_pos\n",
    "            end = start + len(word)\n",
    "            word_boundaries.append((start, end))\n",
    "            current_pos = end\n",
    "        \n",
    "        # Map each token to a word\n",
    "        aligned_labels = []\n",
    "        special_tokens_mask = encoding['special_tokens_mask'][0].tolist()\n",
    "        \n",
    "        for idx, (start, end) in enumerate(offset_mapping.tolist()):\n",
    "            if special_tokens_mask[idx] or (start == 0 and end == 0):\n",
    "                aligned_labels.append(-100)\n",
    "            else:\n",
    "                word_idx = None\n",
    "                for w_idx, (w_start, w_end) in enumerate(word_boundaries):\n",
    "                    if start >= w_start and start < w_end:\n",
    "                        word_idx = w_idx\n",
    "                        break\n",
    "                \n",
    "                if word_idx is not None and word_idx < len(bio_tags):\n",
    "                    tag = bio_tags[word_idx]\n",
    "                    # Convert B- to I- for continuation tokens\n",
    "                    if start > word_boundaries[word_idx][0] and tag.startswith('B-'):\n",
    "                        tag = 'I-' + tag[2:]\n",
    "                    aligned_labels.append(TAG_TO_IDX.get(tag, TAG_TO_IDX['O']))\n",
    "                else:\n",
    "                    aligned_labels.append(TAG_TO_IDX['O'])\n",
    "        \n",
    "        return torch.tensor(aligned_labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for per-tool intent labels.\"\"\"\n",
    "    return {\n",
    "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
    "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
    "        'tool_labels': torch.stack([x['tool_labels'] for x in batch]),\n",
    "        'intent_label_character': torch.stack([x['intent_label_character'] for x in batch]),\n",
    "        'intent_label_session': torch.stack([x['intent_label_session'] for x in batch]),\n",
    "        'intent_label_rulebook': torch.stack([x['intent_label_rulebook'] for x in batch]),\n",
    "        'ner_labels': torch.stack([x['ner_labels'] for x in batch]),\n",
    "        'tools': [x['tools'] for x in batch],\n",
    "        'intents': [x['intents'] for x in batch]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c31a9",
   "metadata": {},
   "source": [
    "## 4. Two-Stage Joint Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51107641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStageJointModel(DebertaV2PreTrainedModel):\n",
    "    \"\"\"\n",
    "    Two-Stage Joint DeBERTa-v3 Model.\n",
    "    \n",
    "    Stage 1 (Query-intrinsic):\n",
    "        - Tool Classification: Which tools are needed? (multi-label, 3 classes)\n",
    "        - NER: What entities are mentioned? (BIO tagging with CRF)\n",
    "    \n",
    "    Stage 2 (Context-dependent, gated by tool selection):\n",
    "        - Per-tool Intent Classification:\n",
    "            - character_data: 10 intents (softmax)\n",
    "            - session_notes: 20 intents (softmax)\n",
    "            - rulebook: 30 intents (softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config, num_tools=3, num_ner_tags=25, \n",
    "                 num_character_intents=10, num_session_intents=20, num_rulebook_intents=30):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.num_tools = num_tools\n",
    "        self.num_ner_tags = num_ner_tags\n",
    "        self.num_character_intents = num_character_intents\n",
    "        self.num_session_intents = num_session_intents\n",
    "        self.num_rulebook_intents = num_rulebook_intents\n",
    "        \n",
    "        # Shared encoder\n",
    "        self.deberta = DebertaV2Model(config)\n",
    "        \n",
    "        # Dropout\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout \n",
    "            if hasattr(config, 'classifier_dropout') and config.classifier_dropout is not None\n",
    "            else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # ========== STAGE 1 HEADS ==========\n",
    "        # Tool classification head (multi-label with sigmoid)\n",
    "        self.tool_classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size, num_tools)\n",
    "        )\n",
    "        \n",
    "        # NER head (standard token classification, no CRF for stability)\n",
    "        self.ner_classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_ner_tags)\n",
    "        )\n",
    "        \n",
    "        # ========== STAGE 2 HEADS (Per-Tool Intent) ==========\n",
    "        # Each head outputs softmax over that tool's intents\n",
    "        self.character_intent_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_character_intents)\n",
    "        )\n",
    "        \n",
    "        self.session_intent_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_session_intents)\n",
    "        )\n",
    "        \n",
    "        self.rulebook_intent_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_rulebook_intents)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.post_init()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        tool_labels=None,\n",
    "        intent_label_character=None,\n",
    "        intent_label_session=None,\n",
    "        intent_label_rulebook=None,\n",
    "        ner_labels=None,\n",
    "        stage='all',  # 'stage1', 'stage2', or 'all'\n",
    "        return_dict=True\n",
    "    ):\n",
    "        # Get encoder outputs (shared for both stages)\n",
    "        outputs = self.deberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state  # (batch, seq_len, hidden)\n",
    "        cls_output = sequence_output[:, 0, :]  # (batch, hidden)\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        \n",
    "        # ========== STAGE 1: Tools + NER ==========\n",
    "        tool_logits = self.tool_classifier(cls_output)  # (batch, num_tools)\n",
    "        ner_logits = self.ner_classifier(sequence_output)  # (batch, seq_len, num_tags)\n",
    "        \n",
    "        # ========== STAGE 2: Per-Tool Intents (gated) ==========\n",
    "        character_intent_logits = None\n",
    "        session_intent_logits = None\n",
    "        rulebook_intent_logits = None\n",
    "        \n",
    "        if stage in ['stage2', 'all']:\n",
    "            # Always compute all intent logits (needed for inference)\n",
    "            # Loss masking handles non-selected tools\n",
    "            character_intent_logits = self.character_intent_head(cls_output)\n",
    "            session_intent_logits = self.session_intent_head(cls_output)\n",
    "            rulebook_intent_logits = self.rulebook_intent_head(cls_output)\n",
    "        \n",
    "        # ========== COMPUTE LOSSES ==========\n",
    "        loss = None\n",
    "        tool_loss = None\n",
    "        ner_loss = None\n",
    "        character_intent_loss = None\n",
    "        session_intent_loss = None\n",
    "        rulebook_intent_loss = None\n",
    "        \n",
    "        # Tool loss (BCE for multi-label)\n",
    "        if tool_labels is not None:\n",
    "            tool_loss = F.binary_cross_entropy_with_logits(tool_logits, tool_labels)\n",
    "        \n",
    "        # NER loss (CrossEntropy with ignore_index=-100)\n",
    "        if ner_labels is not None:\n",
    "            # Flatten for CrossEntropy: (batch * seq_len, num_tags) vs (batch * seq_len,)\n",
    "            ner_loss = F.cross_entropy(\n",
    "                ner_logits.view(-1, self.num_ner_tags),\n",
    "                ner_labels.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "        \n",
    "        # Per-tool intent losses (CrossEntropy with ignore_index=-100)\n",
    "        if stage in ['stage2', 'all']:\n",
    "            ce_loss = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            \n",
    "            if intent_label_character is not None:\n",
    "                # Only compute if there are valid labels (not all -100)\n",
    "                valid_mask = intent_label_character != -100\n",
    "                if valid_mask.any():\n",
    "                    character_intent_loss = ce_loss(\n",
    "                        character_intent_logits[valid_mask],\n",
    "                        intent_label_character[valid_mask]\n",
    "                    )\n",
    "            \n",
    "            if intent_label_session is not None:\n",
    "                valid_mask = intent_label_session != -100\n",
    "                if valid_mask.any():\n",
    "                    session_intent_loss = ce_loss(\n",
    "                        session_intent_logits[valid_mask],\n",
    "                        intent_label_session[valid_mask]\n",
    "                    )\n",
    "            \n",
    "            if intent_label_rulebook is not None:\n",
    "                valid_mask = intent_label_rulebook != -100\n",
    "                if valid_mask.any():\n",
    "                    rulebook_intent_loss = ce_loss(\n",
    "                        rulebook_intent_logits[valid_mask],\n",
    "                        intent_label_rulebook[valid_mask]\n",
    "                    )\n",
    "        \n",
    "        # Combine losses based on training stage\n",
    "        if stage == 'stage1':\n",
    "            if tool_loss is not None and ner_loss is not None:\n",
    "                loss = (\n",
    "                    CONFIG['tool_loss_weight'] * tool_loss +\n",
    "                    CONFIG['ner_loss_weight'] * ner_loss\n",
    "                )\n",
    "        elif stage in ['stage2', 'all']:\n",
    "            # Sum all available losses\n",
    "            loss_components = []\n",
    "            if tool_loss is not None:\n",
    "                loss_components.append(CONFIG['tool_loss_weight'] * tool_loss)\n",
    "            if ner_loss is not None:\n",
    "                loss_components.append(CONFIG['ner_loss_weight'] * ner_loss)\n",
    "            \n",
    "            # Intent losses (may be None if no samples for that tool in batch)\n",
    "            intent_losses = [l for l in [character_intent_loss, session_intent_loss, rulebook_intent_loss] if l is not None]\n",
    "            if intent_losses:\n",
    "                # Average intent losses and weight\n",
    "                avg_intent_loss = sum(intent_losses) / len(intent_losses)\n",
    "                loss_components.append(CONFIG['intent_loss_weight'] * avg_intent_loss)\n",
    "            \n",
    "            if loss_components:\n",
    "                loss = sum(loss_components)\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'tool_loss': tool_loss,\n",
    "            'ner_loss': ner_loss,\n",
    "            'character_intent_loss': character_intent_loss,\n",
    "            'session_intent_loss': session_intent_loss,\n",
    "            'rulebook_intent_loss': rulebook_intent_loss,\n",
    "            'tool_logits': tool_logits,\n",
    "            'ner_logits': ner_logits,\n",
    "            'character_intent_logits': character_intent_logits,\n",
    "            'session_intent_logits': session_intent_logits,\n",
    "            'rulebook_intent_logits': rulebook_intent_logits,\n",
    "        }\n",
    "    \n",
    "    def decode_ner(self, ner_logits, attention_mask):\n",
    "        \"\"\"Decode NER predictions using argmax.\"\"\"\n",
    "        # Simple argmax decoding (no CRF)\n",
    "        return ner_logits.argmax(dim=-1).tolist()\n",
    "    \n",
    "    def freeze_intent_heads(self):\n",
    "        \"\"\"Freeze intent heads for Stage 1 training.\"\"\"\n",
    "        for param in self.character_intent_head.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.session_intent_head.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.rulebook_intent_head.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_intent_heads(self):\n",
    "        \"\"\"Unfreeze intent heads for Stage 2 training.\"\"\"\n",
    "        for param in self.character_intent_head.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.session_intent_head.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.rulebook_intent_head.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab24f7",
   "metadata": {},
   "source": [
    "## 5. Initialize Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and config\n",
    "print(f\"Loading model: {CONFIG['model_name']}\")\n",
    "tokenizer = DebertaV2TokenizerFast.from_pretrained(CONFIG['model_name'])\n",
    "config = AutoConfig.from_pretrained(CONFIG['model_name'])\n",
    "config.classifier_dropout = CONFIG['classifier_dropout']\n",
    "\n",
    "# Initialize model with per-tool intent counts\n",
    "model = TwoStageJointModel.from_pretrained(\n",
    "    CONFIG['model_name'],\n",
    "    config=config,\n",
    "    num_tools=len(TOOLS),\n",
    "    num_ner_tags=len(TAG_TO_IDX),\n",
    "    num_character_intents=NUM_INTENTS_PER_TOOL['character_data'],\n",
    "    num_session_intents=NUM_INTENTS_PER_TOOL['session_notes'],\n",
    "    num_rulebook_intents=NUM_INTENTS_PER_TOOL['rulebook'],\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model size\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Print head sizes\n",
    "print(f\"\\nIntent head sizes:\")\n",
    "print(f\"  character_data: {NUM_INTENTS_PER_TOOL['character_data']} classes\")\n",
    "print(f\"  session_notes: {NUM_INTENTS_PER_TOOL['session_notes']} classes\")\n",
    "print(f\"  rulebook: {NUM_INTENTS_PER_TOOL['rulebook']} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18cef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = TwoStageDataset(train_data, tokenizer, CONFIG['max_length'])\n",
    "val_dataset = TwoStageDataset(val_data, tokenizer, CONFIG['max_length'])\n",
    "test_dataset = TwoStageDataset(test_data, tokenizer, CONFIG['max_length'])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Verify a batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  input_ids: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"  tool_labels: {sample_batch['tool_labels'].shape}\")\n",
    "print(f\"  intent_label_character: {sample_batch['intent_label_character'].shape}\")\n",
    "print(f\"  intent_label_session: {sample_batch['intent_label_session'].shape}\")\n",
    "print(f\"  intent_label_rulebook: {sample_batch['intent_label_rulebook'].shape}\")\n",
    "print(f\"  ner_labels: {sample_batch['ner_labels'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312e567",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, stage='stage1'):\n",
    "    \"\"\"\n",
    "    Get optimizer with appropriate parameter groups.\n",
    "    \n",
    "    - Encoder uses base learning rate\n",
    "    - Classification heads use higher learning rate\n",
    "    - Stage 1: intent heads are frozen\n",
    "    \"\"\"\n",
    "    no_decay = ['bias', 'LayerNorm.weight', 'layernorm.weight']\n",
    "    \n",
    "    # Group parameters\n",
    "    encoder_params = []\n",
    "    stage1_head_params = []  # tool + ner heads\n",
    "    stage2_head_params = []  # intent heads\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'deberta' in name:\n",
    "            encoder_params.append((name, param))\n",
    "        elif 'tool_classifier' in name or 'ner_classifier' in name or 'crf' in name:\n",
    "            stage1_head_params.append((name, param))\n",
    "        else:  # intent heads\n",
    "            stage2_head_params.append((name, param))\n",
    "    \n",
    "    optimizer_grouped_parameters = [\n",
    "        # Encoder with weight decay\n",
    "        {\n",
    "            'params': [p for n, p in encoder_params if not any(nd in n for nd in no_decay)],\n",
    "            'lr': CONFIG['learning_rate'],\n",
    "            'weight_decay': CONFIG['weight_decay']\n",
    "        },\n",
    "        # Encoder without weight decay\n",
    "        {\n",
    "            'params': [p for n, p in encoder_params if any(nd in n for nd in no_decay)],\n",
    "            'lr': CONFIG['learning_rate'],\n",
    "            'weight_decay': 0.0\n",
    "        },\n",
    "        # Stage 1 heads (tool + NER)\n",
    "        {\n",
    "            'params': [p for n, p in stage1_head_params if not any(nd in n for nd in no_decay)],\n",
    "            'lr': CONFIG['head_learning_rate'],\n",
    "            'weight_decay': CONFIG['weight_decay']\n",
    "        },\n",
    "        {\n",
    "            'params': [p for n, p in stage1_head_params if any(nd in n for nd in no_decay)],\n",
    "            'lr': CONFIG['head_learning_rate'],\n",
    "            'weight_decay': 0.0\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Only include intent heads if not stage1\n",
    "    if stage != 'stage1':\n",
    "        optimizer_grouped_parameters.extend([\n",
    "            {\n",
    "                'params': [p for n, p in stage2_head_params if not any(nd in n for nd in no_decay)],\n",
    "                'lr': CONFIG['head_learning_rate'],\n",
    "                'weight_decay': CONFIG['weight_decay']\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in stage2_head_params if any(nd in n for nd in no_decay)],\n",
    "                'lr': CONFIG['head_learning_rate'],\n",
    "                'weight_decay': 0.0\n",
    "            },\n",
    "        ])\n",
    "    \n",
    "    return torch.optim.AdamW(optimizer_grouped_parameters)\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, num_training_steps, warmup_ratio=0.1):\n",
    "    \"\"\"Get linear scheduler with warmup.\"\"\"\n",
    "    warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "    return get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a87e59",
   "metadata": {},
   "source": [
    "## 7. Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device, stage='all'):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation/test set.\n",
    "    \n",
    "    Returns metrics for:\n",
    "    - Tool classification (F1, exact match)\n",
    "    - Per-tool intent accuracy\n",
    "    - NER (entity-level F1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Collectors\n",
    "    all_tool_preds = []\n",
    "    all_tool_labels = []\n",
    "    \n",
    "    # Per-tool intent collectors\n",
    "    character_intent_preds = []\n",
    "    character_intent_labels = []\n",
    "    session_intent_preds = []\n",
    "    session_intent_labels = []\n",
    "    rulebook_intent_preds = []\n",
    "    rulebook_intent_labels = []\n",
    "    \n",
    "    # NER collectors\n",
    "    all_ner_preds = []\n",
    "    all_ner_labels = []\n",
    "    \n",
    "    # Loss tracking\n",
    "    total_loss = 0\n",
    "    total_tool_loss = 0\n",
    "    total_ner_loss = 0\n",
    "    total_intent_losses = {'character': 0, 'session': 0, 'rulebook': 0}\n",
    "    intent_loss_counts = {'character': 0, 'session': 0, 'rulebook': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            tool_labels = batch['tool_labels'].to(device)\n",
    "            intent_label_character = batch['intent_label_character'].to(device)\n",
    "            intent_label_session = batch['intent_label_session'].to(device)\n",
    "            intent_label_rulebook = batch['intent_label_rulebook'].to(device)\n",
    "            ner_labels = batch['ner_labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                tool_labels=tool_labels,\n",
    "                intent_label_character=intent_label_character,\n",
    "                intent_label_session=intent_label_session,\n",
    "                intent_label_rulebook=intent_label_rulebook,\n",
    "                ner_labels=ner_labels,\n",
    "                stage=stage\n",
    "            )\n",
    "            \n",
    "            if outputs['loss'] is not None:\n",
    "                total_loss += outputs['loss'].item()\n",
    "            if outputs['tool_loss'] is not None:\n",
    "                total_tool_loss += outputs['tool_loss'].item()\n",
    "            if outputs['ner_loss'] is not None:\n",
    "                total_ner_loss += outputs['ner_loss'].item()\n",
    "            \n",
    "            # Track intent losses\n",
    "            if outputs['character_intent_loss'] is not None:\n",
    "                total_intent_losses['character'] += outputs['character_intent_loss'].item()\n",
    "                intent_loss_counts['character'] += 1\n",
    "            if outputs['session_intent_loss'] is not None:\n",
    "                total_intent_losses['session'] += outputs['session_intent_loss'].item()\n",
    "                intent_loss_counts['session'] += 1\n",
    "            if outputs['rulebook_intent_loss'] is not None:\n",
    "                total_intent_losses['rulebook'] += outputs['rulebook_intent_loss'].item()\n",
    "                intent_loss_counts['rulebook'] += 1\n",
    "            \n",
    "            # Tool predictions (threshold 0.5)\n",
    "            tool_preds = (torch.sigmoid(outputs['tool_logits']) > 0.5).float()\n",
    "            all_tool_preds.append(tool_preds.cpu())\n",
    "            all_tool_labels.append(tool_labels.cpu())\n",
    "            \n",
    "            # Per-tool intent predictions (argmax)\n",
    "            if stage in ['stage2', 'all'] and outputs['character_intent_logits'] is not None:\n",
    "                # Character intents\n",
    "                valid_char = intent_label_character != -100\n",
    "                if valid_char.any():\n",
    "                    char_preds = outputs['character_intent_logits'][valid_char].argmax(dim=-1)\n",
    "                    character_intent_preds.extend(char_preds.cpu().tolist())\n",
    "                    character_intent_labels.extend(intent_label_character[valid_char].cpu().tolist())\n",
    "                \n",
    "                # Session intents\n",
    "                valid_sess = intent_label_session != -100\n",
    "                if valid_sess.any():\n",
    "                    sess_preds = outputs['session_intent_logits'][valid_sess].argmax(dim=-1)\n",
    "                    session_intent_preds.extend(sess_preds.cpu().tolist())\n",
    "                    session_intent_labels.extend(intent_label_session[valid_sess].cpu().tolist())\n",
    "                \n",
    "                # Rulebook intents\n",
    "                valid_rule = intent_label_rulebook != -100\n",
    "                if valid_rule.any():\n",
    "                    rule_preds = outputs['rulebook_intent_logits'][valid_rule].argmax(dim=-1)\n",
    "                    rulebook_intent_preds.extend(rule_preds.cpu().tolist())\n",
    "                    rulebook_intent_labels.extend(intent_label_rulebook[valid_rule].cpu().tolist())\n",
    "            \n",
    "            # NER predictions (argmax decode)\n",
    "            ner_preds = model.decode_ner(outputs['ner_logits'], attention_mask)\n",
    "            \n",
    "            # Convert to tag sequences for seqeval\n",
    "            for pred_seq, label_seq in zip(ner_preds, ner_labels.cpu().tolist()):\n",
    "                pred_tags = []\n",
    "                label_tags = []\n",
    "                for pred_tag, label_tag in zip(pred_seq, label_seq):\n",
    "                    if label_tag != -100:\n",
    "                        pred_tags.append(IDX_TO_TAG[pred_tag])\n",
    "                        label_tags.append(IDX_TO_TAG[label_tag])\n",
    "                if pred_tags:\n",
    "                    all_ner_preds.append(pred_tags)\n",
    "                    all_ner_labels.append(label_tags)\n",
    "    \n",
    "    # Compute metrics\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # Tool metrics\n",
    "    all_tool_preds = torch.cat(all_tool_preds, dim=0).numpy()\n",
    "    all_tool_labels = torch.cat(all_tool_labels, dim=0).numpy()\n",
    "    tool_f1 = f1_score(all_tool_labels, all_tool_preds, average='micro', zero_division=0)\n",
    "    tool_precision = precision_score(all_tool_labels, all_tool_preds, average='micro', zero_division=0)\n",
    "    tool_recall = recall_score(all_tool_labels, all_tool_preds, average='micro', zero_division=0)\n",
    "    tool_exact_match = np.mean(np.all(all_tool_preds == all_tool_labels, axis=1))\n",
    "    \n",
    "    # Per-tool intent accuracy\n",
    "    character_intent_acc = accuracy_score(character_intent_labels, character_intent_preds) if character_intent_labels else 0.0\n",
    "    session_intent_acc = accuracy_score(session_intent_labels, session_intent_preds) if session_intent_labels else 0.0\n",
    "    rulebook_intent_acc = accuracy_score(rulebook_intent_labels, rulebook_intent_preds) if rulebook_intent_labels else 0.0\n",
    "    \n",
    "    # Average intent accuracy\n",
    "    intent_accs = [acc for acc in [character_intent_acc, session_intent_acc, rulebook_intent_acc] if acc > 0]\n",
    "    avg_intent_acc = np.mean(intent_accs) if intent_accs else 0.0\n",
    "    \n",
    "    # NER F1 (using seqeval for entity-level)\n",
    "    ner_f1 = seqeval_f1(all_ner_labels, all_ner_preds, average='micro', zero_division=0) if all_ner_labels else 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': total_loss / num_batches if num_batches > 0 else 0,\n",
    "        'tool_loss': total_tool_loss / num_batches if num_batches > 0 else 0,\n",
    "        'ner_loss': total_ner_loss / num_batches if num_batches > 0 else 0,\n",
    "        'tool_f1': tool_f1,\n",
    "        'tool_precision': tool_precision,\n",
    "        'tool_recall': tool_recall,\n",
    "        'tool_exact_match': tool_exact_match,\n",
    "        'character_intent_acc': character_intent_acc,\n",
    "        'session_intent_acc': session_intent_acc,\n",
    "        'rulebook_intent_acc': rulebook_intent_acc,\n",
    "        'avg_intent_acc': avg_intent_acc,\n",
    "        'ner_f1': ner_f1,\n",
    "    }\n",
    "    \n",
    "    # Add per-tool intent losses\n",
    "    for tool in ['character', 'session', 'rulebook']:\n",
    "        if intent_loss_counts[tool] > 0:\n",
    "            metrics[f'{tool}_intent_loss'] = total_intent_losses[tool] / intent_loss_counts[tool]\n",
    "        else:\n",
    "            metrics[f'{tool}_intent_loss'] = 0.0\n",
    "    \n",
    "    return metrics, (all_ner_labels, all_ner_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0adfced",
   "metadata": {},
   "source": [
    "## 8. Training Loop (Staged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2501711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device, stage='all'):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_tool_loss = 0\n",
    "    total_ner_loss = 0\n",
    "    total_intent_loss = 0\n",
    "    intent_batch_count = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Training ({stage})\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tool_labels = batch['tool_labels'].to(device)\n",
    "        intent_label_character = batch['intent_label_character'].to(device)\n",
    "        intent_label_session = batch['intent_label_session'].to(device)\n",
    "        intent_label_rulebook = batch['intent_label_rulebook'].to(device)\n",
    "        ner_labels = batch['ner_labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            tool_labels=tool_labels,\n",
    "            intent_label_character=intent_label_character,\n",
    "            intent_label_session=intent_label_session,\n",
    "            intent_label_rulebook=intent_label_rulebook,\n",
    "            ner_labels=ner_labels,\n",
    "            stage=stage\n",
    "        )\n",
    "        \n",
    "        loss = outputs['loss']\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if outputs['tool_loss'] is not None:\n",
    "            total_tool_loss += outputs['tool_loss'].item()\n",
    "        if outputs['ner_loss'] is not None:\n",
    "            total_ner_loss += outputs['ner_loss'].item()\n",
    "        \n",
    "        # Track intent losses\n",
    "        intent_losses = [l for l in [outputs['character_intent_loss'], \n",
    "                                      outputs['session_intent_loss'], \n",
    "                                      outputs['rulebook_intent_loss']] if l is not None]\n",
    "        if intent_losses:\n",
    "            total_intent_loss += sum(l.item() for l in intent_losses) / len(intent_losses)\n",
    "            intent_batch_count += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'tool': f\"{outputs['tool_loss'].item():.4f}\" if outputs['tool_loss'] else \"N/A\",\n",
    "            'ner': f\"{outputs['ner_loss'].item():.4f}\" if outputs['ner_loss'] else \"N/A\",\n",
    "        })\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    return {\n",
    "        'loss': total_loss / num_batches,\n",
    "        'tool_loss': total_tool_loss / num_batches,\n",
    "        'ner_loss': total_ner_loss / num_batches,\n",
    "        'intent_loss': total_intent_loss / intent_batch_count if intent_batch_count > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb59f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STAGED TRAINING ==========\n",
    "# Stage 1: Tool + NER only (freeze intent heads)\n",
    "# Stage 2: Joint training (unfreeze intent heads)\n",
    "# Stage 3: Fine-tuning (lower learning rate)\n",
    "\n",
    "training_history = []\n",
    "best_combined_score = 0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 1: Training Tool + NER heads (intent heads frozen)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Freeze intent heads for Stage 1\n",
    "model.freeze_intent_heads()\n",
    "\n",
    "# Stage 1 optimizer (excludes intent heads)\n",
    "stage1_steps = len(train_loader) * CONFIG['stage1_epochs']\n",
    "optimizer = get_optimizer(model, stage='stage1')\n",
    "scheduler = get_scheduler(optimizer, stage1_steps, CONFIG['warmup_ratio'])\n",
    "\n",
    "for epoch in range(CONFIG['stage1_epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{CONFIG['stage1_epochs']} (Stage 1)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    train_metrics = train_epoch(model, train_loader, optimizer, scheduler, device, stage='stage1')\n",
    "    val_metrics, _ = evaluate(model, val_loader, device, stage='stage1')\n",
    "    \n",
    "    # Stage 1 score: tool + NER\n",
    "    stage1_score = (val_metrics['tool_f1'] + val_metrics['ner_f1']) / 2\n",
    "    \n",
    "    history_entry = {\n",
    "        'epoch': epoch + 1,\n",
    "        'stage': 'stage1',\n",
    "        'train_loss': train_metrics['loss'],\n",
    "        'val_loss': val_metrics['loss'],\n",
    "        'val_tool_f1': val_metrics['tool_f1'],\n",
    "        'val_tool_exact_match': val_metrics['tool_exact_match'],\n",
    "        'val_ner_f1': val_metrics['ner_f1'],\n",
    "        'val_avg_intent_acc': 0.0,  # Not computed in stage 1\n",
    "        'stage_score': stage1_score\n",
    "    }\n",
    "    training_history.append(history_entry)\n",
    "    \n",
    "    print(f\"Train Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"Val Tool F1: {val_metrics['tool_f1']:.4f} (Exact Match: {val_metrics['tool_exact_match']:.4f})\")\n",
    "    print(f\"Val NER F1: {val_metrics['ner_f1']:.4f}\")\n",
    "    print(f\"Stage 1 Score: {stage1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf217325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STAGE 2: Joint Training ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STAGE 2: Joint training (all heads)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Unfreeze intent heads\n",
    "model.unfreeze_intent_heads()\n",
    "\n",
    "# Stage 2 optimizer (includes all parameters)\n",
    "stage2_steps = len(train_loader) * CONFIG['stage2_epochs']\n",
    "optimizer = get_optimizer(model, stage='stage2')\n",
    "scheduler = get_scheduler(optimizer, stage2_steps, CONFIG['warmup_ratio'])\n",
    "\n",
    "for epoch in range(CONFIG['stage2_epochs']):\n",
    "    global_epoch = CONFIG['stage1_epochs'] + epoch + 1\n",
    "    print(f\"\\nEpoch {global_epoch}/{CONFIG['stage1_epochs'] + CONFIG['stage2_epochs'] + CONFIG['finetune_epochs']} (Stage 2)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    train_metrics = train_epoch(model, train_loader, optimizer, scheduler, device, stage='all')\n",
    "    val_metrics, _ = evaluate(model, val_loader, device, stage='all')\n",
    "    \n",
    "    # Combined score: tool + NER + intent\n",
    "    combined_score = (\n",
    "        val_metrics['tool_f1'] + \n",
    "        val_metrics['ner_f1'] + \n",
    "        val_metrics['avg_intent_acc']\n",
    "    ) / 3\n",
    "    \n",
    "    history_entry = {\n",
    "        'epoch': global_epoch,\n",
    "        'stage': 'stage2',\n",
    "        'train_loss': train_metrics['loss'],\n",
    "        'val_loss': val_metrics['loss'],\n",
    "        'val_tool_f1': val_metrics['tool_f1'],\n",
    "        'val_tool_exact_match': val_metrics['tool_exact_match'],\n",
    "        'val_ner_f1': val_metrics['ner_f1'],\n",
    "        'val_avg_intent_acc': val_metrics['avg_intent_acc'],\n",
    "        'val_character_intent_acc': val_metrics['character_intent_acc'],\n",
    "        'val_session_intent_acc': val_metrics['session_intent_acc'],\n",
    "        'val_rulebook_intent_acc': val_metrics['rulebook_intent_acc'],\n",
    "        'stage_score': combined_score\n",
    "    }\n",
    "    training_history.append(history_entry)\n",
    "    \n",
    "    print(f\"Train Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"Val Tool F1: {val_metrics['tool_f1']:.4f} (Exact Match: {val_metrics['tool_exact_match']:.4f})\")\n",
    "    print(f\"Val NER F1: {val_metrics['ner_f1']:.4f}\")\n",
    "    print(f\"Val Intent Accuracy: {val_metrics['avg_intent_acc']:.4f}\")\n",
    "    print(f\"  - Character: {val_metrics['character_intent_acc']:.4f}\")\n",
    "    print(f\"  - Session: {val_metrics['session_intent_acc']:.4f}\")\n",
    "    print(f\"  - Rulebook: {val_metrics['rulebook_intent_acc']:.4f}\")\n",
    "    print(f\"Combined Score: {combined_score:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if combined_score > best_combined_score:\n",
    "        best_combined_score = combined_score\n",
    "        patience_counter = 0\n",
    "        \n",
    "        model.save_pretrained(MODEL_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_PATH)\n",
    "        \n",
    "        # Save config and mappings\n",
    "        with open(MODEL_PATH / 'training_config.json', 'w') as f:\n",
    "            json.dump(CONFIG, f, indent=2)\n",
    "        \n",
    "        with open(MODEL_PATH / 'label_mappings.json', 'w') as f:\n",
    "            json.dump(LABEL_MAPPINGS, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n✓ New best model saved! Combined Score: {combined_score:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"\\n✗ No improvement. Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "    \n",
    "    if patience_counter >= CONFIG['patience']:\n",
    "        print(f\"\\nEarly stopping triggered!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STAGE 3: Fine-tuning ==========\n",
    "if patience_counter < CONFIG['patience']:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"STAGE 3: Fine-tuning (lower learning rate)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Lower learning rate for fine-tuning\n",
    "    finetune_lr = CONFIG['learning_rate'] / 10\n",
    "    finetune_head_lr = CONFIG['head_learning_rate'] / 10\n",
    "    \n",
    "    # Update CONFIG temporarily for fine-tuning\n",
    "    original_lr = CONFIG['learning_rate']\n",
    "    original_head_lr = CONFIG['head_learning_rate']\n",
    "    CONFIG['learning_rate'] = finetune_lr\n",
    "    CONFIG['head_learning_rate'] = finetune_head_lr\n",
    "    \n",
    "    stage3_steps = len(train_loader) * CONFIG['finetune_epochs']\n",
    "    optimizer = get_optimizer(model, stage='stage2')\n",
    "    scheduler = get_scheduler(optimizer, stage3_steps, CONFIG['warmup_ratio'])\n",
    "    \n",
    "    # Restore CONFIG\n",
    "    CONFIG['learning_rate'] = original_lr\n",
    "    CONFIG['head_learning_rate'] = original_head_lr\n",
    "    \n",
    "    for epoch in range(CONFIG['finetune_epochs']):\n",
    "        global_epoch = CONFIG['stage1_epochs'] + CONFIG['stage2_epochs'] + epoch + 1\n",
    "        print(f\"\\nEpoch {global_epoch}/{CONFIG['stage1_epochs'] + CONFIG['stage2_epochs'] + CONFIG['finetune_epochs']} (Fine-tune)\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, scheduler, device, stage='all')\n",
    "        val_metrics, _ = evaluate(model, val_loader, device, stage='all')\n",
    "        \n",
    "        combined_score = (\n",
    "            val_metrics['tool_f1'] + \n",
    "            val_metrics['ner_f1'] + \n",
    "            val_metrics['avg_intent_acc']\n",
    "        ) / 3\n",
    "        \n",
    "        history_entry = {\n",
    "            'epoch': global_epoch,\n",
    "            'stage': 'finetune',\n",
    "            'train_loss': train_metrics['loss'],\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'val_tool_f1': val_metrics['tool_f1'],\n",
    "            'val_tool_exact_match': val_metrics['tool_exact_match'],\n",
    "            'val_ner_f1': val_metrics['ner_f1'],\n",
    "            'val_avg_intent_acc': val_metrics['avg_intent_acc'],\n",
    "            'val_character_intent_acc': val_metrics['character_intent_acc'],\n",
    "            'val_session_intent_acc': val_metrics['session_intent_acc'],\n",
    "            'val_rulebook_intent_acc': val_metrics['rulebook_intent_acc'],\n",
    "            'stage_score': combined_score\n",
    "        }\n",
    "        training_history.append(history_entry)\n",
    "        \n",
    "        print(f\"Train Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"Val Tool F1: {val_metrics['tool_f1']:.4f}\")\n",
    "        print(f\"Val NER F1: {val_metrics['ner_f1']:.4f}\")\n",
    "        print(f\"Val Intent Accuracy: {val_metrics['avg_intent_acc']:.4f}\")\n",
    "        print(f\"Combined Score: {combined_score:.4f}\")\n",
    "        \n",
    "        if combined_score > best_combined_score:\n",
    "            best_combined_score = combined_score\n",
    "            patience_counter = 0\n",
    "            \n",
    "            model.save_pretrained(MODEL_PATH)\n",
    "            tokenizer.save_pretrained(MODEL_PATH)\n",
    "            print(f\"\\n✓ New best model saved! Combined Score: {combined_score:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"\\n✗ No improvement. Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "        \n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"\\nEarly stopping triggered!\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Training complete! Best Combined Score: {best_combined_score:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f671f",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d271dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for testing\n",
    "print(\"Loading best model for final evaluation...\")\n",
    "model = TwoStageJointModel.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_tools=len(TOOLS),\n",
    "    num_ner_tags=len(TAG_TO_IDX),\n",
    "    num_character_intents=NUM_INTENTS_PER_TOOL['character_data'],\n",
    "    num_session_intents=NUM_INTENTS_PER_TOOL['session_notes'],\n",
    "    num_rulebook_intents=NUM_INTENTS_PER_TOOL['rulebook']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics, (ner_labels, ner_preds) = evaluate(model, test_loader, device, stage='all')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n📊 Tool Classification:\")\n",
    "print(f\"  F1 Score: {test_metrics['tool_f1']:.4f}\")\n",
    "print(f\"  Precision: {test_metrics['tool_precision']:.4f}\")\n",
    "print(f\"  Recall: {test_metrics['tool_recall']:.4f}\")\n",
    "print(f\"  Exact Match: {test_metrics['tool_exact_match']:.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 Intent Classification (Per-Tool Accuracy):\")\n",
    "print(f\"  Character Data: {test_metrics['character_intent_acc']:.4f}\")\n",
    "print(f\"  Session Notes: {test_metrics['session_intent_acc']:.4f}\")\n",
    "print(f\"  Rulebook: {test_metrics['rulebook_intent_acc']:.4f}\")\n",
    "print(f\"  Average: {test_metrics['avg_intent_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\n🏷️ NER (Entity Extraction):\")\n",
    "print(f\"  F1 Score: {test_metrics['ner_f1']:.4f}\")\n",
    "\n",
    "# Combined score\n",
    "combined_test_score = (\n",
    "    test_metrics['tool_f1'] + \n",
    "    test_metrics['ner_f1'] + \n",
    "    test_metrics['avg_intent_acc']\n",
    ") / 3\n",
    "print(f\"\\n⭐ Combined Test Score: {combined_test_score:.4f}\")\n",
    "\n",
    "# Detailed NER report\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"Detailed NER Classification Report:\")\n",
    "print(\"-\" * 40)\n",
    "print(classification_report(ner_labels, ner_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25636047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test results\n",
    "test_results = {\n",
    "    'model_name': CONFIG['model_name'],\n",
    "    'test_metrics': test_metrics,\n",
    "    'training_history': training_history,\n",
    "    'best_combined_score': best_combined_score,\n",
    "    'config': CONFIG\n",
    "}\n",
    "\n",
    "with open(MODEL_PATH / 'test_results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Test results saved to {MODEL_PATH}/test_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a530f",
   "metadata": {},
   "source": [
    "## 10. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe69b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs = [h['epoch'] for h in training_history]\n",
    "\n",
    "# Color-code by stage\n",
    "stage_colors = {'stage1': 'blue', 'stage2': 'green', 'finetune': 'orange'}\n",
    "colors = [stage_colors[h['stage']] for h in training_history]\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs, [h['train_loss'] for h in training_history], 'b-', label='Train', alpha=0.7)\n",
    "axes[0, 0].plot(epochs, [h['val_loss'] for h in training_history], 'r-', label='Validation', alpha=0.7)\n",
    "# Add stage boundaries\n",
    "stage1_end = CONFIG['stage1_epochs']\n",
    "stage2_end = CONFIG['stage1_epochs'] + CONFIG['stage2_epochs']\n",
    "axes[0, 0].axvline(x=stage1_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].axvline(x=stage2_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training & Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tool F1\n",
    "axes[0, 1].plot(epochs, [h['val_tool_f1'] for h in training_history], 'g-', marker='o', markersize=4)\n",
    "axes[0, 1].axvline(x=stage1_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].axvline(x=stage2_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('F1 Score')\n",
    "axes[0, 1].set_title('Tool Classification F1')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "\n",
    "# Intent Accuracy (only available from Stage 2)\n",
    "intent_epochs = [h['epoch'] for h in training_history if h['stage'] != 'stage1']\n",
    "intent_accs = [h['val_avg_intent_acc'] for h in training_history if h['stage'] != 'stage1']\n",
    "if intent_epochs:\n",
    "    axes[1, 0].plot(intent_epochs, intent_accs, 'm-', marker='o', markersize=4)\n",
    "    # Also plot per-tool accuracies\n",
    "    char_accs = [h.get('val_character_intent_acc', 0) for h in training_history if h['stage'] != 'stage1']\n",
    "    sess_accs = [h.get('val_session_intent_acc', 0) for h in training_history if h['stage'] != 'stage1']\n",
    "    rule_accs = [h.get('val_rulebook_intent_acc', 0) for h in training_history if h['stage'] != 'stage1']\n",
    "    axes[1, 0].plot(intent_epochs, char_accs, 'b--', alpha=0.5, label='Character')\n",
    "    axes[1, 0].plot(intent_epochs, sess_accs, 'g--', alpha=0.5, label='Session')\n",
    "    axes[1, 0].plot(intent_epochs, rule_accs, 'r--', alpha=0.5, label='Rulebook')\n",
    "    axes[1, 0].legend(loc='lower right')\n",
    "axes[1, 0].axvline(x=stage2_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].set_title('Intent Classification Accuracy')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "\n",
    "# NER F1\n",
    "axes[1, 1].plot(epochs, [h['val_ner_f1'] for h in training_history], 'c-', marker='o', markersize=4)\n",
    "axes[1, 1].axvline(x=stage1_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].axvline(x=stage2_end + 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].set_title('NER F1 Score')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "\n",
    "# Add stage labels\n",
    "for ax in axes.flat:\n",
    "    ax.text(stage1_end/2, ax.get_ylim()[1]*0.95, 'Stage 1', ha='center', fontsize=8, alpha=0.7)\n",
    "    ax.text((stage1_end + stage2_end)/2, ax.get_ylim()[1]*0.95, 'Stage 2', ha='center', fontsize=8, alpha=0.7)\n",
    "    if len(epochs) > stage2_end:\n",
    "        ax.text((stage2_end + max(epochs))/2, ax.get_ylim()[1]*0.95, 'Fine-tune', ha='center', fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_PATH / 'training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Training history plot saved to {MODEL_PATH}/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf060a5",
   "metadata": {},
   "source": [
    "## 11. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b81440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, text, device):\n",
    "    \"\"\"\n",
    "    Run inference on a single query.\n",
    "    \n",
    "    Returns:\n",
    "        dict with tools, intents (per selected tool), and entities\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=CONFIG['max_length'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, stage='all')\n",
    "    \n",
    "    # Tool predictions (threshold 0.5)\n",
    "    tool_probs = torch.sigmoid(outputs['tool_logits']).cpu().numpy()[0]\n",
    "    predicted_tools = [TOOLS[i] for i, p in enumerate(tool_probs) if p > 0.5]\n",
    "    \n",
    "    # Per-tool intent predictions (only for selected tools)\n",
    "    predicted_intents = {}\n",
    "    \n",
    "    if 'character_data' in predicted_tools:\n",
    "        char_intent_idx = outputs['character_intent_logits'].argmax(dim=-1).item()\n",
    "        char_intent = IDX_TO_INTENT_PER_TOOL['character_data'][str(char_intent_idx)]\n",
    "        predicted_intents['character_data'] = char_intent\n",
    "    \n",
    "    if 'session_notes' in predicted_tools:\n",
    "        sess_intent_idx = outputs['session_intent_logits'].argmax(dim=-1).item()\n",
    "        sess_intent = IDX_TO_INTENT_PER_TOOL['session_notes'][str(sess_intent_idx)]\n",
    "        predicted_intents['session_notes'] = sess_intent\n",
    "    \n",
    "    if 'rulebook' in predicted_tools:\n",
    "        rule_intent_idx = outputs['rulebook_intent_logits'].argmax(dim=-1).item()\n",
    "        rule_intent = IDX_TO_INTENT_PER_TOOL['rulebook'][str(rule_intent_idx)]\n",
    "        predicted_intents['rulebook'] = rule_intent\n",
    "    \n",
    "    # NER predictions (CRF decode)\n",
    "    ner_preds = model.decode_ner(outputs['ner_emissions'], attention_mask)[0]\n",
    "    \n",
    "    # Extract entities from predictions\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_type = None\n",
    "    \n",
    "    for i, (token, tag_idx) in enumerate(zip(tokens, ner_preds)):\n",
    "        # Skip special tokens\n",
    "        if token in ['[CLS]', '[SEP]', '[PAD]', '<s>', '</s>', '<pad>']:\n",
    "            continue\n",
    "        \n",
    "        tag = IDX_TO_TAG[tag_idx]\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Save previous entity if exists\n",
    "            if current_entity:\n",
    "                entities.append({'text': current_entity.strip(), 'type': current_type})\n",
    "            # Start new entity\n",
    "            current_entity = token.replace('▁', ' ').replace('##', '')\n",
    "            current_type = tag[2:]\n",
    "        elif tag.startswith('I-') and current_type == tag[2:]:\n",
    "            # Continue current entity\n",
    "            current_entity += token.replace('▁', ' ').replace('##', '')\n",
    "        else:\n",
    "            # End current entity\n",
    "            if current_entity:\n",
    "                entities.append({'text': current_entity.strip(), 'type': current_type})\n",
    "            current_entity = None\n",
    "            current_type = None\n",
    "    \n",
    "    # Don't forget last entity\n",
    "    if current_entity:\n",
    "        entities.append({'text': current_entity.strip(), 'type': current_type})\n",
    "    \n",
    "    return {\n",
    "        'query': text,\n",
    "        'tools': predicted_tools,\n",
    "        'tool_probs': {TOOLS[i]: float(p) for i, p in enumerate(tool_probs)},\n",
    "        'intents': predicted_intents,\n",
    "        'entities': entities\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with example queries\n",
    "test_queries = [\n",
    "    \"What's my armor class and how does Shield work?\",\n",
    "    \"Did we meet anyone named the Archmage in our last session?\",\n",
    "    \"How much damage does Fireball do and can I cast it at 5th level?\",\n",
    "    \"What are my spell slots and did we find any magic items last time?\",\n",
    "    \"Tell me about the Beholder's legendary actions\",\n",
    "    \"What happened when we fought the dragon?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = predict(model, tokenizer, query, device)\n",
    "    \n",
    "    print(f\"\\n📝 Query: \\\"{query}\\\"\")\n",
    "    print(f\"   🔧 Tools: {result['tools']}\")\n",
    "    print(f\"   📊 Tool Probs: {', '.join(f'{k}: {v:.2f}' for k, v in result['tool_probs'].items())}\")\n",
    "    print(f\"   🎯 Intents: {result['intents']}\")\n",
    "    print(f\"   🏷️ Entities: {result['entities']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b033c8",
   "metadata": {},
   "source": [
    "## 12. Export Inference Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08758b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standalone inference module\n",
    "inference_code = '''\"\"\"\n",
    "Two-Stage Joint DeBERTa Model - Inference Module\n",
    "\n",
    "Usage:\n",
    "    from inference import TwoStageInference\n",
    "    \n",
    "    model = TwoStageInference(\"path/to/model\")\n",
    "    result = model.predict(\"What's my AC and how does Fireball work?\")\n",
    "    print(result)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DebertaV2TokenizerFast, DebertaV2Model, DebertaV2PreTrainedModel\n",
    "\n",
    "\n",
    "class TwoStageJointModel(DebertaV2PreTrainedModel):\n",
    "    \"\"\"Two-Stage Joint DeBERTa-v3 Model.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, num_tools=3, num_ner_tags=25, \n",
    "                 num_character_intents=10, num_session_intents=20, num_rulebook_intents=30):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.num_tools = num_tools\n",
    "        self.num_ner_tags = num_ner_tags\n",
    "        self.num_character_intents = num_character_intents\n",
    "        self.num_session_intents = num_session_intents\n",
    "        self.num_rulebook_intents = num_rulebook_intents\n",
    "        \n",
    "        self.deberta = DebertaV2Model(config)\n",
    "        \n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout \n",
    "            if hasattr(config, 'classifier_dropout') and config.classifier_dropout is not None\n",
    "            else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Stage 1 heads\n",
    "        self.tool_classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size, num_tools)\n",
    "        )\n",
    "        \n",
    "        self.ner_classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_ner_tags)\n",
    "        )\n",
    "        \n",
    "        # Stage 2 heads\n",
    "        self.character_intent_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_character_intents)\n",
    "        )\n",
    "        \n",
    "        self.session_intent_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_session_intents)\n",
    "        )\n",
    "        \n",
    "        self.rulebook_intent_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(config.hidden_size // 2, num_rulebook_intents)\n",
    "        )\n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, **kwargs):\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        cls_output = self.dropout(sequence_output[:, 0, :])\n",
    "        \n",
    "        return {\n",
    "            'tool_logits': self.tool_classifier(cls_output),\n",
    "            'ner_logits': self.ner_classifier(sequence_output),\n",
    "            'character_intent_logits': self.character_intent_head(cls_output),\n",
    "            'session_intent_logits': self.session_intent_head(cls_output),\n",
    "            'rulebook_intent_logits': self.rulebook_intent_head(cls_output),\n",
    "        }\n",
    "    \n",
    "    def decode_ner(self, ner_logits, attention_mask):\n",
    "        \"\"\"Decode NER predictions using argmax.\"\"\"\n",
    "        return ner_logits.argmax(dim=-1).tolist()\n",
    "\n",
    "\n",
    "class TwoStageInference:\n",
    "    \"\"\"Inference wrapper for the Two-Stage Joint Model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load mappings\n",
    "        with open(f'{model_path}/label_mappings.json') as f:\n",
    "            self.mappings = json.load(f)\n",
    "        \n",
    "        self.tools = list(self.mappings['tool_to_idx'].keys())\n",
    "        self.idx_to_tag = {int(k): v for k, v in self.mappings['idx_to_tag'].items()}\n",
    "        self.idx_to_intent_per_tool = self.mappings['idx_to_intent_per_tool']\n",
    "        \n",
    "        # Load config\n",
    "        with open(f'{model_path}/training_config.json') as f:\n",
    "            self.config = json.load(f)\n",
    "        \n",
    "        # Load model\n",
    "        self.tokenizer = DebertaV2TokenizerFast.from_pretrained(model_path)\n",
    "        self.model = TwoStageJointModel.from_pretrained(\n",
    "            model_path,\n",
    "            num_tools=len(self.tools),\n",
    "            num_ner_tags=len(self.mappings['tag_to_idx']),\n",
    "            num_character_intents=self.mappings['num_intents_per_tool']['character_data'],\n",
    "            num_session_intents=self.mappings['num_intents_per_tool']['session_notes'],\n",
    "            num_rulebook_intents=self.mappings['num_intents_per_tool']['rulebook']\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Run inference on a query.\"\"\"\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.config['max_length'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Tools\n",
    "        tool_probs = torch.sigmoid(outputs['tool_logits']).cpu().numpy()[0]\n",
    "        predicted_tools = [self.tools[i] for i, p in enumerate(tool_probs) if p > 0.5]\n",
    "        \n",
    "        # Intents (per selected tool)\n",
    "        intents = {}\n",
    "        if 'character_data' in predicted_tools:\n",
    "            idx = outputs['character_intent_logits'].argmax(dim=-1).item()\n",
    "            intents['character_data'] = self.idx_to_intent_per_tool['character_data'][str(idx)]\n",
    "        if 'session_notes' in predicted_tools:\n",
    "            idx = outputs['session_intent_logits'].argmax(dim=-1).item()\n",
    "            intents['session_notes'] = self.idx_to_intent_per_tool['session_notes'][str(idx)]\n",
    "        if 'rulebook' in predicted_tools:\n",
    "            idx = outputs['rulebook_intent_logits'].argmax(dim=-1).item()\n",
    "            intents['rulebook'] = self.idx_to_intent_per_tool['rulebook'][str(idx)]\n",
    "        \n",
    "        # Entities\n",
    "        ner_preds = self.model.decode_ner(outputs['ner_logits'], attention_mask)[0]\n",
    "        entities = self._extract_entities(input_ids[0], ner_preds)\n",
    "        \n",
    "        return {\n",
    "            'tools': predicted_tools,\n",
    "            'intents': intents,\n",
    "            'entities': entities\n",
    "        }\n",
    "    \n",
    "    def _extract_entities(self, input_ids, ner_preds):\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        current_type = None\n",
    "        \n",
    "        for token, tag_idx in zip(tokens, ner_preds):\n",
    "            if token in ['[CLS]', '[SEP]', '[PAD]', '<s>', '</s>', '<pad>']:\n",
    "                continue\n",
    "            \n",
    "            tag = self.idx_to_tag[tag_idx]\n",
    "            \n",
    "            if tag.startswith('B-'):\n",
    "                if current_entity:\n",
    "                    entities.append({'text': current_entity.strip(), 'type': current_type})\n",
    "                current_entity = token.replace('▁', ' ').replace('##', '')\n",
    "                current_type = tag[2:]\n",
    "            elif tag.startswith('I-') and current_type == tag[2:]:\n",
    "                current_entity += token.replace('▁', ' ').replace('##', '')\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append({'text': current_entity.strip(), 'type': current_type})\n",
    "                current_entity = None\n",
    "                current_type = None\n",
    "        \n",
    "        if current_entity:\n",
    "            entities.append({'text': current_entity.strip(), 'type': current_type})\n",
    "        \n",
    "        return entities\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python inference.py 'Your query here'\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    model = TwoStageInference(\".\")\n",
    "    result = model.predict(sys.argv[1])\n",
    "    print(json.dumps(result, indent=2))\n",
    "'''\n",
    "\n",
    "with open(MODEL_PATH / 'inference.py', 'w') as f:\n",
    "    f.write(inference_code)\n",
    "\n",
    "print(f\"✓ Inference module saved to {MODEL_PATH}/inference.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee74559",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook trained a **Two-Stage Joint DeBERTa-v3 Model** for D&D query understanding:\n",
    "\n",
    "### Architecture\n",
    "- **Shared Encoder**: DeBERTa-v3-base (86M params)\n",
    "- **Stage 1 Heads**: Tool Classification (3 classes) + NER with CRF (25 BIO tags)\n",
    "- **Stage 2 Heads**: Per-tool Intent Classification (10 + 20 + 30 = 60 intents)\n",
    "\n",
    "### Training Strategy\n",
    "1. **Stage 1 (Epochs 1-3)**: Train Tool + NER heads only (intent heads frozen)\n",
    "2. **Stage 2 (Epochs 4-10)**: Joint training of all heads\n",
    "3. **Fine-tuning (Epochs 11-15)**: Lower learning rate for refinement\n",
    "\n",
    "### Key Differences from Flat Architecture\n",
    "- ✅ Per-tool intent heads instead of single 61-class head\n",
    "- ✅ Gated intent prediction (only compute for selected tools)\n",
    "- ✅ Masked intent loss (ignore non-selected tools)\n",
    "- ✅ Staged training for better tool/NER convergence first\n",
    "\n",
    "### Model Saved To\n",
    "- `models/two_stage_joint/`\n",
    "  - `pytorch_model.bin` - Model weights\n",
    "  - `config.json` - Model config\n",
    "  - `tokenizer.json` - Tokenizer\n",
    "  - `label_mappings.json` - All label mappings\n",
    "  - `training_config.json` - Training hyperparameters\n",
    "  - `test_results.json` - Final evaluation metrics\n",
    "  - `training_history.png` - Training curves\n",
    "  - `inference.py` - Standalone inference module"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
